{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Web APIs and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project involves the use of Natural Language Processing and Computer Modelling along with Web APIs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Statement: Introduce the concept of natural language to students using data gathered by visiting two subrebbits from the reddit website to create a text filled dataset comprised of the titles of approximately 1000 post from each subreddits. The dataset will be transformed via natural language processing tools to a form that can be used by models to catagorize the titles into the correct subreddits from which they came. CountVectorizer and TfidfVectorizer will be tried for the transformations and the test models will be Logisitic Regression, KNNeighbors,MultinomialNB, DecisionTree, RandomForests,BaggingClassifier, ADABoost, and Support Vector Machines. The results will be scored according to accuracy on training and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import all necessary packages and libraries for data collection,cleaning, transformation,modelling and visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import  cross_val_score,train_test_split, GridSearchCV\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import regex as re\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier,RandomForestClassifier;\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was used to visit the reddit websites to collect the data required. The data has been saved to a csv to avoid having to repull this information from the reddit site. Since there is no reason to pull more data, the code has been disabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define URL and username\n",
    "#url_name = \"https://www.reddit.com/r/movies.json\" # change subreddit here\n",
    "#username = {\"User-agent\": 'boom-deva'}      # header to prevent 429 error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to pull subreddit posts\n",
    "#def get_subreddit(url, n_pulls, headers):    \n",
    "\n",
    "    # Create empty templates\n",
    "    #posts = []\n",
    "    #after = None\n",
    "\n",
    "    # Create a loop that does max 25 requests per pull\n",
    "    #for pull_num in range(n_pulls):\n",
    "        #print(\"Pulling data attempted\", pull_num+1,\"time(s)\")\n",
    "\n",
    "        #if after == None:\n",
    "            #new_url = url                 # base case\n",
    "        #else:\n",
    "            #new_url = url+\"?after=\"+after # subsequent iterations\n",
    "\n",
    "        #res = requests.get(new_url, headers=headers)\n",
    "\n",
    "        #if res.status_code == 200:\n",
    "            #subreddit_json = res.json()                      # Pull JSON\n",
    "            #posts.extend(subreddit_json['data']['children']) # Get subreddit posts\n",
    "            #after = subreddit_json['data']['after']          # 'after' = ID of the last post in this iteration\n",
    "        #else:\n",
    "           # print(\"We've run into an error. The status code is:\", res.status_code)\n",
    "            #break\n",
    "\n",
    "        #time.sleep(1)\n",
    "        \n",
    "    #return(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function\n",
    "#post_movies = get_subreddit(url_name, n_pulls = 40, headers = username)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#post_movies[0]['data']['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movie_titles = []\n",
    "#for i in range(len(post_movies)):\n",
    "    #re.sub(\"[^a-zA-Z]\",           # The pattern to search for\n",
    "                      #\" \",                   # The pattern to replace it with\n",
    "      # post_movies[i][\"data\"]['title'] )   # The text to search                                    \n",
    "    \n",
    "    #movie_titles.append(post_movies[i][\"data\"]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define URL and username\n",
    "#url_name = \"https://www.reddit.com/r/television.json\" # change subreddit here\n",
    "#username = {\"User-agent\": 'boom-deva'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function\n",
    "#post_television = get_subreddit(url_name, n_pulls = 40, headers = username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#post_television[0]['data']['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tv_titles = []\n",
    "#for i in range(len(post_television)):\n",
    "    #tv_titles.append(post_television[i][\"data\"]['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next section of code has also been disabled. It was used to clean the data of punctuation and empty spaces. Also the stemmer was employed to cull the features. The cleaned data were then collected into lists TV and Movie, turned into dictionaries and then dataframes that were saved to csv a file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate object of class PorterStemmer.\n",
    "#p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def string_to_words(string_word):\n",
    "    # Function to convert a string of words\n",
    "    # The input is a single string (subreddit post title), and \n",
    "    # the output is a single string (a preprocessed title)\n",
    "    \n",
    "    \n",
    "    # 1. Remove non-letters.\n",
    "    #letters_only = re.sub(\"[^a-zA-Z]\", \" \", string_word)\n",
    "    \n",
    "    #2 P-stemmer\n",
    "    #stemmed = p_stemmer.stem(letters_only)\n",
    "    \n",
    "    # 3. Convert to lower case, split into individual words.\n",
    "    #words = stemmed.lower().split()\n",
    "    \n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    # a list, so convert the stop words to a set.\n",
    "    #stops = set()This is where I could have inserted a custom \n",
    "    #set of stop words, perhaps for a different challenge\n",
    "\n",
    "    \n",
    "    # 5. Remove stop words.\n",
    "    #meaningful_words = [w for w in words if not w in stops]\n",
    "    \n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    #return (\" \".join(meaningful_words))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_movie_titles = []\n",
    "#clean_tv_titles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through the movie titles list and apply stemmer, remove \n",
    "#punctuation, spaces,and non letters , set to lower case\n",
    "#for movie_title in movie_titles:\n",
    "    # Convert title to words, then append to clean_movue_titles.\n",
    "    #clean_movie_titles.append(string_to_words(movie_title))        \n",
    "    \n",
    "#for tv_title in tv_titles:\n",
    "    # Convert title to words, then append to clean_tv_titles.\n",
    "    #clean_tv_titles.append(string_to_words(tv_title))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dictionary for preprocessed movie titles\n",
    "#movie_titles_dict = {index:title for index,title\n",
    "                     #in enumerate(clean_movie_titles)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dictionary for preprocessed television titles\n",
    "#television_titles_dict = {index:title for index,title\n",
    "                          #in enumerate(clean_tv_titles)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframes from the movie dictionary\n",
    "#movie_df = pd.DataFrame(movie_titles_dict.values(), index = movie_titles_dict.keys(), columns = [\"Title\"])\n",
    "#movie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create dataframe from the television dictionary\n",
    "#tv_df = pd.DataFrame(television_titles_dict.values(), index = television_titles_dict.keys(), columns = [\"Title\"])\n",
    "#tv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movie_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tv_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding column for target movie =0 , tv =1\n",
    "#movie_df['source'] = 0\n",
    "#tv_df['source'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining the movie and tv dataframes\n",
    "#reddit = [movie_df , tv_df]\n",
    "#df = pd.concat(reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#looking at a piece of the combined data\n",
    "#df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"./reddit.csv\")  \n",
    "#saving final merged file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These lines are reading the csv back into the notebook, dropping the extra \"Unnamed\" column , also necessary to reverse designation for source column because TV is the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./reddit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source'] = df['source'].replace({0:1,1:0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the cleaned data. The source column shows 0 for movie post and 1 for tv post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>detective pikachu official chinese post</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poster for joker with joaquin phoenix</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lindsay ellis video essay on the making of pet...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>superbad to the oscars jonah hill s evolution ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>john hughes directed movies sixteen candles th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  source\n",
       "0            detective pikachu official chinese post       0\n",
       "1              poster for joker with joaquin phoenix       0\n",
       "2  lindsay ellis video essay on the making of pet...       0\n",
       "3  superbad to the oscars jonah hill s evolution ...       0\n",
       "4  john hughes directed movies sixteen candles th...       0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1950 entries, 0 to 1949\n",
      "Data columns (total 2 columns):\n",
      "Title     1950 non-null object\n",
      "source    1950 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 30.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The csv file saved data and  target together. This code seperates them into x for data and y for the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['source']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Baseline Score TV is 0.508 of the total, what we could expect to see without a model, percentage of majority class present in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.508718\n",
       "0    0.491282\n",
       "Name: source, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This shows the percentage of TV posts vs movie posts\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is split into two portions a set to train the models on (75% of total) and a set to test the models on(25% of total), a random state is set to maintain consistency of outcomes and stratify is used to maintain relative breakdown of the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct a train/test split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.25,\n",
    "                                                    random_state = 42,\n",
    "                                                     stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train  is 1    0.508892\n",
      "0    0.491108\n",
      "Name: source, dtype: float64\n",
      "y_test mean is 1    0.508197\n",
      "0    0.491803\n",
      "Name: source, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#checking that the train and test distributions \n",
    "#for the target variable are similar\n",
    "print('y_train  is',y_train.value_counts(normalize=True))\n",
    "print('y_test mean is',y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data in X_train and X_test are the cleaned tv and movie titles. The vectorizers will return a a vector of counts for the number of times each word or phrase appears in the data organized by row for the titles and words/phrases in the columns. The models will then look for patterns to determine whether the row is a movie or tv post. All of the models are classification models since the target is discrete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizers and Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression with Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like linear regression this model seeks to find a line of best fit, in this case the line is between 0 and 1, not to infinity as with the linear model.This model seeks to predict binary outcomes and has a few parameters that can be adjusted, the penalty l1(Lasso),l2(Ridge)and C for inverse regularization strength."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline allows the Vectorizer and Model to be implemented sequentially together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline([    #combines two instantiating but order counts\n",
    "    ('cvec', CountVectorizer()), # order counts , put model second\n",
    "    ('lr',LogisticRegression()) #used in combination with Gridsearch\n",
    "                                # to test all of those param tuning\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline is used in conjunction with Gridsearch to allow hyperparameter tuning for both the vectorizer and the model.The parameters in this situation are stop words english or none, maximum features to be included, ngram- whether to look at single words or more, regularization strength, and penalty-to help reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9158686730506156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 2500,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english',\n",
       " 'lr__C': 150,\n",
       " 'lr__penalty': 'l2'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune GridSearchCV\n",
    "pipe_params ={\n",
    "    'cvec__stop_words':[None,'english'],\n",
    "    'cvec__max_features':[1500,2500,3000],\n",
    "    'cvec__ngram_range':[(1,1),(1,2)],\n",
    "    'lr__C':[50,100,150],\n",
    "    'lr__penalty':['l1','l2']\n",
    "}\n",
    "gs = GridSearchCV(pipe_lr, param_grid = pipe_params,cv=5)\n",
    "gs.fit(X_train,y_train);\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the cell above can generate a cross val score and training and test scores as well as the optimal parameters of the choices allowed. The scores are being collecting for comparision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cvec_cross=gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train score\n",
    "lr_cvec_train=gs.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "lr_cvec_test=gs.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dataframe to house all of the scores of all of the combinations-there will be 16 sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "headings =['Models','CrossValScores','Training Scores','Test Scores']\n",
    "lr_cvec =['LogisticRegression/CountVectorizer',lr_cvec_cross,lr_cvec_train,lr_cvec_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(lr_cvec,headings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression with TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach will be the same for all the combinations. Tfidf differs from Count Vectorizer in that Tfidf rewards rare words more than common ones and so could have a different result as that may cause a model to focus more on the rare words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr_tf = Pipeline([    #combines two instantiating but order counts\n",
    "    ('tf', TfidfVectorizer()), # order counts , put model second\n",
    "    ('lr',LogisticRegression()) #used in combination with Gridsearch\n",
    "                                # to test all of those param tuning\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9247606019151847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lr__C': 10,\n",
       " 'lr__penalty': 'l2',\n",
       " 'tf__max_features': 5000,\n",
       " 'tf__ngram_range': (1, 1),\n",
       " 'tf__stop_words': None}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune GridSearchCV\n",
    "pipe_params ={\n",
    "    'tf__stop_words':[None,'english'],\n",
    "    'tf__max_features':[1000,3000,5000],\n",
    "    'tf__ngram_range':[(1,1),(1,2)],\n",
    "    'lr__C':[0.1,1,10],\n",
    "    'lr__penalty':['l1','l2']\n",
    "}\n",
    "gs = GridSearchCV(pipe_lr_tf, param_grid = pipe_params,cv=5)\n",
    "gs.fit(X_train,y_train);\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CV Score\n",
    "lr_tf_cross = gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train score\n",
    "lr_tf_train = gs.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "lr_tf_test = gs.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the scores to the results df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tf =['LogisticRegression/TfidfVectorizer',lr_tf_cross,lr_tf_train,lr_tf_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[1]=lr_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNNeighbors with Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNNeighbors is a model that uses distance and number of neighbors in neighborhood to arrive at at conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_knn = Pipeline([    #combines two instantiating but order counts\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('knn',KNeighborsClassifier())])                       # order counts , put model second\n",
    "     #used in combination with Gridsearch\n",
    "                                # to test all of those param tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.780437756497948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 1750,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english',\n",
       " 'knn__n_neighbors': 5,\n",
       " 'knn__p': 1}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #Tune GridSearchCV\n",
    "pipe_params ={\n",
    "    'cvec__stop_words':[None,'english'],\n",
    "    'cvec__max_features':[750,1250,1750],\n",
    "    'cvec__ngram_range':[(1,1),(1,2)],\n",
    "    'knn__n_neighbors':[3,5,11],\n",
    "    'knn__p':[1,2]}\n",
    "\n",
    "gs = GridSearchCV(pipe_knn, param_grid = pipe_params,cv=3)\n",
    "gs.fit(X_train,y_train);\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Val score\n",
    "knn_cvec_cross = gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train score\n",
    "knn_cvec_train = gs.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "knn_cvec_test = gs.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results being added to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cvec =['KNNeighbors/CountVectorizer',knn_cvec_cross,knn_cvec_train,knn_cvec_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[2]=knn_cvec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNNeighbors with TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_knn_tf = Pipeline([    #combines two instantiating but order counts\n",
    "    ('tf', TfidfVectorizer()),\n",
    "    ('knn',KNeighborsClassifier())])                       # order counts , put model second\n",
    "     #used in combination with Gridsearch\n",
    "                                # to test all of those param tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7941176470588235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn__n_neighbors': 5,\n",
       " 'knn__p': 2,\n",
       " 'tf__max_features': 1000,\n",
       " 'tf__ngram_range': (1, 1),\n",
       " 'tf__stop_words': None}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #Tune GridSearchCV\n",
    "pipe_params ={\n",
    "    'tf__stop_words':[None,'english'],\n",
    "    'tf__max_features':[500,750,1000],\n",
    "    'tf__ngram_range':[(1,1),(1,2)],\n",
    "    'knn__n_neighbors':[3,5,7],\n",
    "    'knn__p':[1,2]}\n",
    "\n",
    "gs = GridSearchCV(pipe_knn_tf, param_grid = pipe_params,cv=3)\n",
    "gs.fit(X_train,y_train);\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Val Score\n",
    "knn_tf_cross = gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train score\n",
    "knn_tf_train = gs.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "knn_tf_test = gs.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results being added to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_tf =['KNNeighbors/TfidfVectorizer',knn_tf_cross,knn_tf_train,knn_tf_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[3]=knn_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial NB with CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Naive Bayes is one of a group of models that uses probabilities(knowing which words in a line of text, courtesy of the vectorizer) to come to a decision. The alpha is a smoothing parameter range 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_nb = Pipeline([('cvec', CountVectorizer()),\n",
    "                    ('nb', MultinomialNB())])    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8912448700410397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 2500,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english',\n",
       " 'nb__alpha': 0.1}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tune GridSearchCV\n",
    "pipe_params ={\n",
    "    'cvec__stop_words':[None,'english'],\n",
    "    'cvec__max_features':[2500,3000,3500],\n",
    "    'cvec__ngram_range':[(1,1),(1,2)],\n",
    "    'nb__alpha': (1, 0.1, 0.01, 0.001, 0.0001, 0.00001)\n",
    "    \n",
    "}\n",
    "gs = GridSearchCV(pipe_nb, param_grid = pipe_params,cv=3)\n",
    "gs.fit(X_train,y_train);\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Val Score\n",
    "nb_cvec_cross = gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train score\n",
    "nb_cvec_train = gs.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "nb_cvec_test = gs.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_cvec =['Multinomial/CountVectorizer',nb_cvec_cross,nb_cvec_train,nb_cvec_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[4]=nb_cvec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultinomialNB with TfidfVectorizor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model can handle the decimals produced by Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_nb_tf = Pipeline([('tf', TfidfVectorizer()),\n",
    "                    ('nb', MultinomialNB())])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9049247606019152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'nb__alpha': 1,\n",
       " 'tf__max_features': 3500,\n",
       " 'tf__ngram_range': (1, 1),\n",
       " 'tf__stop_words': None}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tune GridSearchCV\n",
    "pipe_params ={\n",
    "    'tf__stop_words':[None,'english'],\n",
    "    'tf__max_features':[2500,3000,3500],\n",
    "    'tf__ngram_range':[(1,1),(1,2)],\n",
    "    'nb__alpha': (2,1, 0.1, 0.01, 0.001, 0.0001, 0.00001)\n",
    "    \n",
    "}\n",
    "gs = GridSearchCV(pipe_nb_tf, param_grid = pipe_params,cv=5)\n",
    "gs.fit(X_train,y_train);\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross val Score\n",
    "nb_tf_cross = gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train score\n",
    "nb_tf_train = gs.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "nb_tf_test = gs.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_tf =['Multinomial/TfidfVectorizer',nb_tf_cross,nb_tf_train,nb_tf_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[5]=nb_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classic Decision Tree with Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order counts with decision trees and results can vary, even with the same beginning.There are quite a few parameters available to decision trees. This model used max_depth-how tall the tree should be allowed to grow and max features how many features the tree should be allowed to see at each node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_dt = Pipeline([    #combines two instantiating but order counts\n",
    "    ('cvec', CountVectorizer()), # order counts , put model second\n",
    "    ('dt',DecisionTreeClassifier()) #used in combination with Gridsearch\n",
    "                                # to test all of those param tuning\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8590971272229823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 750,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': None,\n",
       " 'dt__max_depth': 90,\n",
       " 'dt__max_features': 70}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune GridSearchCV\n",
    "pipe_params ={\n",
    "    'cvec__stop_words':[None,'english'],\n",
    "    'cvec__max_features':[500,750,1000],\n",
    "    'cvec__ngram_range':[(1,1),(1,2)],\n",
    "    'dt__max_depth':[70,80,90],\n",
    "    'dt__max_features':[60,70,80]\n",
    "}\n",
    "gs = GridSearchCV(pipe_dt, param_grid = pipe_params,cv=3)\n",
    "gs.fit(X_train,y_train);\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Val Score\n",
    "dt_cvec_cross = gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train score\n",
    "dt_cvec_train = gs.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "dt_cvec_test = gs.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_cvec =['DecisionTree/CountVectorizer',dt_cvec_cross,dt_cvec_train,dt_cvec_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[6]=dt_cvec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classic Decision Tree with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_dt_tf = Pipeline([    #combines two instantiating but order counts\n",
    "    ('tf', TfidfVectorizer()), # order counts , put model second\n",
    "    ('dt',DecisionTreeClassifier()) #used in combination with Gridsearch\n",
    "                                # to test all of those param tuning\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8604651162790697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dt__max_depth': 150,\n",
       " 'dt__max_features': 100,\n",
       " 'tf__max_features': 400,\n",
       " 'tf__ngram_range': (1, 1),\n",
       " 'tf__stop_words': None}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune GridSearchCV\n",
    "pipe_params ={\n",
    "    'tf__stop_words':[None,'english'],\n",
    "    'tf__max_features':[400,500,600],\n",
    "    'tf__ngram_range':[(1,1),(1,2),(2,2)],\n",
    "    'dt__max_depth':[70,110,150],\n",
    "    'dt__max_features':[60,80,100]\n",
    "}\n",
    "gs = GridSearchCV(pipe_dt_tf, param_grid = pipe_params,cv=3)\n",
    "gs.fit(X_train,y_train);\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Val Score\n",
    "dt_tf_cross = gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train score\n",
    "dt_tf_train = gs.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "dt_tf_test = gs.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_tf =['DecisionTree/TfidfVectorizer',dt_tf_cross,dt_tf_train,dt_tf_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[7]=dt_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging Classifier with Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bagging classifier is a variant of decision tree,involving growing multiple trees at the same time on random subsets of features. A decision is arrived at by vote or average. Parameters uses n_estimators -number of trees grown and max features the size of each tree's subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_bag = Pipeline([    #combines two instantiating but order counts\n",
    "    ('cvec', CountVectorizer()), # order counts , put model second\n",
    "    ('bag',BaggingClassifier()) #used in combination with Gridsearch\n",
    "                                # to test all of those param tuning\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8953488372093024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bag__max_features': 750,\n",
       " 'bag__n_estimators': 100,\n",
       " 'cvec__max_features': 2000,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'cvec__stop_words': 'english'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune GridSearchCV for Count Vec with Bagging Classifier\n",
    "pipe_params ={\n",
    "    'cvec__stop_words':[None,'english'],\n",
    "    'cvec__max_features':[1000,1500,2000],\n",
    "    'cvec__ngram_range':[(1,1),(1,2)],\n",
    "    'bag__n_estimators':[10,50,100],\n",
    "    'bag__max_features':[250,500,750]\n",
    "}\n",
    "gs = GridSearchCV(pipe_bag, param_grid = pipe_params,cv=3)\n",
    "gs.fit(X_train,y_train);\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Val Score\n",
    "bag_cvec_cross = gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train score\n",
    "bag_cvec_train = gs.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "bag_cvec_test = gs.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sending results to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_cvec =['Bagging/CountVectorizer',bag_cvec_cross,bag_cvec_train,bag_cvec_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[8]= bag_cvec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging Classifier with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_bag_tf = Pipeline([    #combines two instantiating but order counts\n",
    "    ('tf', TfidfVectorizer()), # order counts , put model second\n",
    "    ('bag',BaggingClassifier()) #used in combination with Gridsearch\n",
    "                                # to test all of those param tuning\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8898768809849521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bag__max_features': 500,\n",
       " 'bag__n_estimators': 50,\n",
       " 'tf__max_features': 1500,\n",
       " 'tf__ngram_range': (1, 1),\n",
       " 'tf__stop_words': 'english'}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune GridSearchCV\n",
    "pipe_params ={\n",
    "    'tf__stop_words':[None,'english'],\n",
    "    'tf__max_features':[500,1000,1500],\n",
    "    'tf__ngram_range':[(1,1),(1,2)],\n",
    "    'bag__n_estimators':[10,50,100],\n",
    "    'bag__max_features':[10,100,500]\n",
    "}\n",
    "gs = GridSearchCV(pipe_bag_tf, param_grid = pipe_params,cv=3)\n",
    "gs.fit(X_train,y_train);\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Val Score\n",
    "bag_tf_cross = gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train score\n",
    "bag_tf_train = gs.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "bag_tf_test = gs.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_tf =['Bagging/TfidfVectorizer',bag_tf_cross,bag_tf_train,bag_tf_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[9]=bag_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADA Boost Classifier with Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADABoost is a decision tree type model where max depth =1 and multiple trees are grown sequentially. This model involves a learning rate parameter and n_estimator parameter for number of trees to grow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_ada = Pipeline([    #combines two instantiating but order counts\n",
    "    ('cvec', CountVectorizer()), # order counts , put model second\n",
    "    ('ada',AdaBoostClassifier()) #used in combination with Gridsearch\n",
    "                                # to test all of those param tuning\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.859781121751026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ada__learning_rate': 1,\n",
       " 'ada__n_estimators': 200,\n",
       " 'cvec__max_features': 2000,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'cvec__stop_words': None}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune GridSearchCV\n",
    "pipe_params ={\n",
    "    'cvec__stop_words':[None,'english'],\n",
    "    'cvec__max_features':[1000,1500,2000],\n",
    "    'cvec__ngram_range':[(1,1),(1,2)],\n",
    "    'ada__n_estimators':[100,150,200],\n",
    "    'ada__learning_rate':[1,1.5,2]\n",
    "}\n",
    "gs = GridSearchCV(pipe_ada, param_grid = pipe_params,cv=3)\n",
    "gs.fit(X_train,y_train);\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Val Score\n",
    "ada_cvec_cross = gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train score\n",
    "ada_cvec_train = gs.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "ada_cvec_test = gs.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sending results to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_cvec =['ADABoost/CountVectorizer',ada_cvec_cross,ada_cvec_train,ada_cvec_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[10]=ada_cvec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADA Booster with Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_ada_tf = Pipeline([    #combines two instantiating but order counts\n",
    "    ('tf', TfidfVectorizer()), # order counts , put model second\n",
    "    ('ada',AdaBoostClassifier()) #used in combination with Gridsearch\n",
    "                                # to test all of those param tuning\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8700410396716827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ada__learning_rate': 1.5,\n",
       " 'ada__n_estimators': 200,\n",
       " 'tf__max_features': 2000,\n",
       " 'tf__ngram_range': (1, 1),\n",
       " 'tf__stop_words': 'english'}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune GridSearchCV\n",
    "pipe_params ={\n",
    "    'tf__stop_words':[None,'english'],\n",
    "    'tf__max_features':[1000,1500,2000],\n",
    "    'tf__ngram_range':[(1,1),(1,2)],\n",
    "    'ada__n_estimators':[100,150,200],\n",
    "    'ada__learning_rate':[1,1.5,2]\n",
    "}\n",
    "gs = GridSearchCV(pipe_ada_tf, param_grid = pipe_params,cv=3)\n",
    "gs.fit(X_train,y_train);\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Val Score\n",
    "ada_tf_cross = gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train score\n",
    "ada_tf_train = gs.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "ada_tf_test = gs.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_tf =['ADABoost/TfidfVectorizer',ada_tf_cross,ada_tf_train,ada_tf_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[11]=ada_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest and Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is also a decision tree based model.This model involves growing trees from randomly chosen subsets of features at each node. The parameters chosen are n_estimators for number of trees, max depth for amount of branching and max features for the number of randomly chosen features available at each node of each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf = Pipeline([    #combines two instantiating but order counts\n",
    "    ('cvec', CountVectorizer()), # order counts , put model second\n",
    "    ('rf',RandomForestClassifier()) #used in combination with Gridsearch\n",
    "                                # to test all of those param tuning\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 432 out of 432 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9015047879616963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 2000,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english',\n",
       " 'rf__max_depth': None,\n",
       " 'rf__max_features': 20,\n",
       " 'rf__n_estimators': 200}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pipe_params = {\n",
    "    'cvec__stop_words':[None,'english'],\n",
    "    'cvec__max_features':[1000,1500,2000],\n",
    "    'cvec__ngram_range':[(1,1),(1,2)],\n",
    "    'rf__n_estimators':[100,200],\n",
    "    'rf__max_depth':[None,3],\n",
    "    'rf__max_features':['auto',10,20]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe_rf, param_grid = pipe_params, cv=3,verbose =1)\n",
    "gs.fit(X_train, y_train);\n",
    "print(gs.best_score_)#this is a cross val score\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Val Score\n",
    "rf_cvec_cross = gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train score\n",
    "rf_cvec_train = gs.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "rf_cvec_test = gs.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cvec =['RandomForest/CountVectorizer',rf_cvec_cross,rf_cvec_train,rf_cvec_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[12]=rf_cvec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest with Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf_tf = Pipeline([    #combines two instantiating but order counts\n",
    "    ('tf', TfidfVectorizer()), # order counts , put model second\n",
    "    ('rf',RandomForestClassifier()) #used in combination with Gridsearch\n",
    "                                # to test all of those param tuning\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 648 out of 648 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8891928864569083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rf__max_depth': None,\n",
       " 'rf__max_features': 10,\n",
       " 'rf__n_estimators': 250,\n",
       " 'tf__max_features': 1500,\n",
       " 'tf__ngram_range': (1, 1),\n",
       " 'tf__stop_words': 'english'}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_params = {\n",
    "    'tf__stop_words':[None,'english'],\n",
    "    'tf__max_features':[500,1000,1500],\n",
    "    'tf__ngram_range':[(1,1),(1,2)],\n",
    "    'rf__n_estimators':[150,200,250],\n",
    "    'rf__max_depth':[None,3],\n",
    "    'rf__max_features':['auto',10,20]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe_rf_tf, param_grid = pipe_params, cv=3,verbose =1)\n",
    "gs.fit(X_train, y_train);\n",
    "print(gs.best_score_)#this is a cross val score\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Val Score\n",
    "rf_tf_cross = gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train score\n",
    "rf_tf_train = gs.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "rf_tf_test = gs.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sending results to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tf =['RandomForest/TfidfVectorizer',rf_tf_cross,rf_tf_train,rf_tf_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[13]=rf_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine with Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines involve adding a dimension to divide the data to facilitate a prediction. The parameters chosen for use with this model are kernel which allows the model to divide the data in different ways, C which is a penaly parameter and gamma which is a coefficient of kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svc = Pipeline([    #combines two instantiating but order counts\n",
    "    ('cvec', CountVectorizer()), # order counts , put model second\n",
    "    ('svc',svm.SVC()) #used in combination with Gridsearch\n",
    "                                # to test all of those param tuning\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 432 candidates, totalling 1296 fits\n",
      "0.8823529411764706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1296 out of 1296 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 1500,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english',\n",
       " 'svc__C': 10,\n",
       " 'svc__gamma': 'auto',\n",
       " 'svc__kernel': 'linear'}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_params = {\n",
    "    'cvec__stop_words':[None,'english'],\n",
    "    'cvec__max_features':[500,1000,1500],\n",
    "    'cvec__ngram_range':[(1,1),(1,2)],\n",
    "    'svc__kernel':['rbf','linear','sigmoid'],\n",
    "    'svc__C':[0.1,1,10,100],\n",
    "    'svc__gamma':['auto',10,20]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe_svc, param_grid = pipe_params, cv=3,verbose =1)\n",
    "gs.fit(X_train, y_train);\n",
    "print(gs.best_score_)#this is a cross val score\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_cvec_cross = gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train score\n",
    "svc_cvec_train = gs.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "svc_cvec_test = gs.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sending results to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_cvec =['SupportVectorMachine/CountVectorizer',svc_cvec_cross,svc_cvec_train,svc_cvec_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[14]= svc_cvec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine with Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svc_tf = Pipeline([    #combines two instantiating but order counts\n",
    "    ('tf', TfidfVectorizer()), # order counts , put model second\n",
    "    ('svc',svm.SVC()) #used in combination with Gridsearch\n",
    "                                # to test all of those param tuning\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 432 candidates, totalling 1296 fits\n",
      "0.8850889192886456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1296 out of 1296 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'svc__C': 100,\n",
       " 'svc__gamma': 'auto',\n",
       " 'svc__kernel': 'linear',\n",
       " 'tf__max_features': 1500,\n",
       " 'tf__ngram_range': (1, 1),\n",
       " 'tf__stop_words': 'english'}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_params = {\n",
    "    'tf__stop_words':[None,'english'],\n",
    "    'tf__max_features':[500,1000,1500],\n",
    "    'tf__ngram_range':[(1,1),(1,2)],\n",
    "    'svc__kernel':['rbf','linear','sigmoid'],\n",
    "    'svc__C':[0.1,1,10,100],\n",
    "    'svc__gamma':['auto',10,20]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe_svc_tf, param_grid = pipe_params, cv=3,verbose =1)\n",
    "gs.fit(X_train, y_train);\n",
    "print(gs.best_score_)#this is a cross val score\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_tf_cross = gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train score\n",
    "svc_tf_train = gs.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "svc_tf_test = gs.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sending results to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_tf =['SupportVectorMachineTfidfVectorizer',svc_tf_cross,svc_tf_train,svc_tf_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[15]= svc_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table houses all of the best results of the vectorizer/classification model trials. The cross val scores show the model perfomance against the validation set(holdout set). The training score shows the model performance versus information the model has seen before. The test scores show the models performance versus unseen data. All the scores are accuracy scores tracking the percent of correct predictions out of all predictions.Accuracy was used as a means of evaluation because the concept of false positives and false negatives are not as impactful in this case. Whether the model could categorize each post correctly is of primary importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>CrossValScores</th>\n",
       "      <th>Training Scores</th>\n",
       "      <th>Test Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression/CountVectorizer</td>\n",
       "      <td>0.915869</td>\n",
       "      <td>0.997948</td>\n",
       "      <td>0.932377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression/TfidfVectorizer</td>\n",
       "      <td>0.924761</td>\n",
       "      <td>0.997948</td>\n",
       "      <td>0.932377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNNeighbors/CountVectorizer</td>\n",
       "      <td>0.780438</td>\n",
       "      <td>0.886457</td>\n",
       "      <td>0.706967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNNeighbors/TfidfVectorizer</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.927497</td>\n",
       "      <td>0.795082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Multinomial/CountVectorizer</td>\n",
       "      <td>0.891245</td>\n",
       "      <td>0.987004</td>\n",
       "      <td>0.895492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Multinomial/TfidfVectorizer</td>\n",
       "      <td>0.904925</td>\n",
       "      <td>0.984952</td>\n",
       "      <td>0.915984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DecisionTree/CountVectorizer</td>\n",
       "      <td>0.859097</td>\n",
       "      <td>0.956908</td>\n",
       "      <td>0.872951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DecisionTree/TfidfVectorizer</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.987004</td>\n",
       "      <td>0.901639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bagging/CountVectorizer</td>\n",
       "      <td>0.895349</td>\n",
       "      <td>0.984952</td>\n",
       "      <td>0.918033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bagging/TfidfVectorizer</td>\n",
       "      <td>0.889877</td>\n",
       "      <td>0.99316</td>\n",
       "      <td>0.936475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ADABoost/CountVectorizer</td>\n",
       "      <td>0.859781</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.903689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ADABoost/TfidfVectorizer</td>\n",
       "      <td>0.870041</td>\n",
       "      <td>0.978112</td>\n",
       "      <td>0.870902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForest/CountVectorizer</td>\n",
       "      <td>0.901505</td>\n",
       "      <td>0.997264</td>\n",
       "      <td>0.936475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForest/TfidfVectorizer</td>\n",
       "      <td>0.889193</td>\n",
       "      <td>0.99316</td>\n",
       "      <td>0.936475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SupportVectorMachine/CountVectorizer</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.99316</td>\n",
       "      <td>0.930328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SupportVectorMachineTfidfVectorizer</td>\n",
       "      <td>0.885089</td>\n",
       "      <td>0.99316</td>\n",
       "      <td>0.934426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Models CrossValScores Training Scores  \\\n",
       "0     LogisticRegression/CountVectorizer       0.915869        0.997948   \n",
       "1     LogisticRegression/TfidfVectorizer       0.924761        0.997948   \n",
       "2            KNNeighbors/CountVectorizer       0.780438        0.886457   \n",
       "3            KNNeighbors/TfidfVectorizer       0.794118        0.927497   \n",
       "4            Multinomial/CountVectorizer       0.891245        0.987004   \n",
       "5            Multinomial/TfidfVectorizer       0.904925        0.984952   \n",
       "6           DecisionTree/CountVectorizer       0.859097        0.956908   \n",
       "7           DecisionTree/TfidfVectorizer       0.860465        0.987004   \n",
       "8                Bagging/CountVectorizer       0.895349        0.984952   \n",
       "9                Bagging/TfidfVectorizer       0.889877         0.99316   \n",
       "10              ADABoost/CountVectorizer       0.859781        0.970588   \n",
       "11              ADABoost/TfidfVectorizer       0.870041        0.978112   \n",
       "12          RandomForest/CountVectorizer       0.901505        0.997264   \n",
       "13          RandomForest/TfidfVectorizer       0.889193         0.99316   \n",
       "14  SupportVectorMachine/CountVectorizer       0.882353         0.99316   \n",
       "15   SupportVectorMachineTfidfVectorizer       0.885089         0.99316   \n",
       "\n",
       "   Test Scores  \n",
       "0     0.932377  \n",
       "1     0.932377  \n",
       "2     0.706967  \n",
       "3     0.795082  \n",
       "4     0.895492  \n",
       "5     0.915984  \n",
       "6     0.872951  \n",
       "7     0.901639  \n",
       "8     0.918033  \n",
       "9     0.936475  \n",
       "10    0.903689  \n",
       "11    0.870902  \n",
       "12    0.936475  \n",
       "13    0.936475  \n",
       "14    0.930328  \n",
       "15    0.934426  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the best performing Vectorizer/Model Combination TfidfVectorizer and Logistic Regression, though many combinations did well in this challenge. Ideally a model's test score would be as high as its training score. For all the combinations the test scores were lower. The best performing model had the smallest gap between cross val, train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our TfidfVectorizer.\n",
    "tf = TfidfVectorizer( max_features=3000,\n",
    "                       stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit our TfidfVectorizer on the training data and transform training data.\n",
    "X_train_tf = pd.DataFrame(tf.fit_transform(X_train).todense()\n",
    "                            ,columns = tf.get_feature_names())\n",
    "#passed in X_train one column as a series because Vectorizer wants series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform our testing data with the already-fit TfidfVectorizer.\n",
    "X_test_tf = pd.DataFrame(tf.transform(X_test).todense()\n",
    "                            ,columns = tf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9385245901639344"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=10,penalty='l2')\n",
    "lr.fit(X_train_tf,y_train)\n",
    "lr.score(X_test_tf,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9979480164158687"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_train_tf,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below shows the first five predictions for the training set. Movie =0 TV=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions.\n",
    "print(f'Predicted values: {lr.predict(X_train_tf.head())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below shows the probabilities of zeroes and ones for the first five rows of the training set, the first number of each pair is the probability of a one , the second a zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probabilities: [[0.98289466 0.01710534]\n",
      " [0.91382522 0.08617478]\n",
      " [0.04819221 0.95180779]\n",
      " [0.89470305 0.10529695]\n",
      " [0.06933373 0.93066627]]\n"
     ]
    }
   ],
   "source": [
    "#gives probability of zeroes and ones\n",
    "print(f'Predicted probabilities: {lr.predict_proba(X_train_tf.head())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line shows the coefficient for each feature(word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Coefficient: [[0.64179815 0.62567279 1.6207947  ... 0.52280547 0.21131464 2.41600012]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Logistic Regression Coefficient: {lr.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line converts those coefficients to a more interpretable form-if the count of a feature were to increase by one the likelhood of success(a number one prediction) increases by that feature's coefficient times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.8998941 ,  1.86950332,  5.05710761, ...,  1.68675315,\n",
       "         1.23530097, 11.20096705]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a vectorizer find out the most important words used in determining the post. This shows the top 10 words in the combined posts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie       28.422275\n",
       "season      22.989202\n",
       "tv          22.944838\n",
       "movies      22.477315\n",
       "official    21.704341\n",
       "netflix     19.587282\n",
       "series      18.511244\n",
       "film        16.697952\n",
       "trailer     16.656592\n",
       "new         16.042490\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq=X_train_tf.sum(axis=0).sort_values(ascending=False).head(10)\n",
    "word_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph shows the same information visually, it is surprising how many posts have movie and tv in the title but for the most part this list makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g=sns.barplot(x=word_freq.index,y=word_freq.values)\n",
    "ax =g\n",
    "plt.title('Word frequency')\n",
    "plt.xlabel('Top words of Movie and TV combined')\n",
    "plt.ylabel('Frequency of Words in Corpora')\n",
    "for p in ax.patches:\n",
    "    ax.annotate(int(p.get_height()), (p.get_x()*1.005,\n",
    "                                      p.get_height()*1.005),\n",
    "                                      fontsize=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:By converting words to counts and looking for patterns, machines can correctly identify the subreddit category the words originally came from. The vectorizer/model combinations performed very well with these two subreddits.There are many more models,vectorizers and parameters to try.Different subreddits with more overlap may provide more chalenges. It may make sense to experiment further eventually leading to a machine that can categorize a post without knowing where it could be filed before beginning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
